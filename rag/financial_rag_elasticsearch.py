# rag/financial_rag_elasticsearch.py
"""
‚ö†Ô∏è ‚ö†Ô∏è ‚ö†Ô∏è ADVERTENCIA - ARCHIVO OBSOLETO ‚ö†Ô∏è ‚ö†Ô∏è ‚ö†Ô∏è

ESTE ARCHIVO YA NO SE USA EN EL PROYECTO PRINCIPAL.

El sistema RAG ahora se ejecuta como MICROSERVICIO independiente.
- El microservicio est√° en: https://rag-search-m70x.onrender.com
- La versi√≥n optimizada est√° en: rag/microservice_optimized.py

CONFIGURACI√ìN ACTUAL:
- El proyecto principal hace llamadas HTTP al microservicio RAG
- Ver agents/financial_agents.py (l√≠nea 64-72) para el cliente
- Ver config.py (l√≠nea 137) para RAG_API_URL

SI NECESITAS ACTUALIZAR EL MICROSERVICIO:
1. Copia rag/microservice_optimized.py al proyecto del microservicio
2. Reinicia el servidor del microservicio

ESTE ARCHIVO SE MANTIENE SOLO COMO REFERENCIA/BACKUP.
NO MODIFICAR ESTE ARCHIVO - USAR microservice_optimized.py

===================================================================

Sistema RAG - VERSI√ìN ELASTICSEARCH CON OPENAI EMBEDDINGS
Actualizado para LangChain 1.0+ con optimizaciones de rendimiento

Los usuarios consultan material financiero indexado en Elasticsearch.
El admin indexa documentos con generate_index.py
"""

from typing import List
from langchain_openai import OpenAIEmbeddings
from langchain_elasticsearch import ElasticsearchStore
from langchain_core.documents import Document
from langchain_core.tools import tool

# Importar configuraci√≥n
from config_elasticsearch import (
    ES_INDEX_NAME,
    EMBEDDING_MODEL,
    EMBEDDING_DIMENSIONS,
    get_elasticsearch_client,
    get_es_config
)

# Importar API key de OpenAI desde config principal
from config import OPENAI_API_KEY

# ========================================
# CLASE RAG ELASTICSEARCH
# ========================================

class FinancialRAGElasticsearch:
    """
    Sistema RAG usando Elasticsearch como vector store con OpenAI Embeddings.
    Solo lectura para usuarios.
    Actualizado para LangChain 1.0+
    """
    
    def __init__(
        self,
        index_name: str = ES_INDEX_NAME,
        embedding_model: str = EMBEDDING_MODEL
    ):
        self.index_name = index_name
        self.embedding_model_name = embedding_model
        
        # Verificar que existe API key
        if not OPENAI_API_KEY:
            raise ValueError(
                "OPENAI_API_KEY no encontrada. "
                "Config√∫rala en .env o Streamlit Secrets."
            )
        
        # Inicializar embeddings de OpenAI
        print(f"üß† Cargando modelo de embeddings OpenAI: {embedding_model}")
        print(f"   Dimensiones: {EMBEDDING_DIMENSIONS}")
        
        self.embeddings = OpenAIEmbeddings(
            model=embedding_model,
            openai_api_key=OPENAI_API_KEY,
            # Par√°metros opcionales para optimizaci√≥n:
            chunk_size=1000,  # N√∫mero de textos por batch
            max_retries=3,
            timeout=30
        )
        
        # Vector store (se conecta a Elasticsearch)
        self.vector_store = None
        
        # N√∫mero de resultados a retornar
        self.k_results = 4
        
        # Conectar autom√°ticamente
        self._connect()
    
    def _connect(self) -> bool:
        """Conecta al √≠ndice de Elasticsearch."""
        try:
            print(f"üì• Conectando a Elasticsearch (√≠ndice: {self.index_name})...")
            
            # Verificar que existe el cliente
            es_client = get_elasticsearch_client()
            if not es_client:
                print("‚ùå No se pudo conectar a Elasticsearch")
                return False
            
            # Verificar que existe el √≠ndice
            if not es_client.indices.exists(index=self.index_name):
                print(f"‚ùå El √≠ndice '{self.index_name}' no existe")
                print("   El administrador debe generar el √≠ndice primero:")
                print("   python admin/generate_index.py")
                return False
            
            # Obtener configuraci√≥n
            es_config = get_es_config()
            
            # Crear ElasticsearchStore (LangChain 1.0 syntax)
            self.vector_store = ElasticsearchStore(
                index_name=self.index_name,
                embedding=self.embeddings,
                es_url=es_config["es_url"],
                es_user=es_config["es_user"],
                es_password=es_config["es_password"]
            )
            
            print(f"‚úÖ Conectado a Elasticsearch (√≠ndice: {self.index_name})")
            
            # Mostrar info del √≠ndice
            count = es_client.count(index=self.index_name)
            print(f"   Documentos indexados: {count['count']}")
            
            return True
        
        except Exception as e:
            print(f"‚ùå Error conectando a Elasticsearch: {e}")
            return False

    def get_health_status(self) -> dict:
        """
        Retorna el estado de salud del sistema RAG.
        Determina el estado basado en el vector_store existente.
        """
        # Inferir estado actual
        is_connected = (
            self.vector_store is not None and
            self.embeddings is not None
        )
        
        # Inferir √∫ltimo error chequeando si _connect() fall√≥
        error_msg = None
        if not is_connected:
            error_msg = "RAG no inicializado o conexi√≥n fallida"
        
        return {
            "connection_status": "connected" if is_connected else "disconnected",
            "last_error": error_msg,
            "retry_count": 0,  # No es cr√≠tico, solo para compatibilidad
            "index_name": self.index_name,
            "embeddings_loaded": self.embeddings is not None,
            "vector_store_ready": self.vector_store is not None
        }

    def search_documents(
        self,
        query: str,
        k: int = None,
        filter_dict: dict = None
    ) -> List[Document]:
        """
        Busca documentos similares a la query en Elasticsearch.
        
        Args:
            query: Consulta de b√∫squeda
            k: N√∫mero de documentos a retornar
            filter_dict: Filtros de metadata (ej: {"cfa_level": "I"})
        
        Returns:
            Lista de documentos relevantes
        """
        if k is None:
            k = self.k_results
        
        # Verificar que est√© conectado
        if self.vector_store is None:
            print("‚ö†Ô∏è No conectado a Elasticsearch. Intentando reconectar...")
            if not self._connect():
                return []
        
        print(f"üîç Buscando en Elasticsearch con OpenAI: '{query}' (top {k})")
        
        try:
            # B√∫squeda sem√°ntica con similarity_search
            if filter_dict:
                results = self.vector_store.similarity_search(
                    query=query,
                    k=k,
                    filter=filter_dict
                )
            else:
                results = self.vector_store.similarity_search(
                    query=query,
                    k=k
                )
            
            print(f"‚úÖ {len(results)} documentos encontrados")
            return results
        
        except Exception as e:
            print(f"‚ùå Error en b√∫squeda: {e}")
            return []


# ========================================
# INSTANCIA GLOBAL
# ========================================

# Instancia √∫nica del sistema RAG
rag_system = FinancialRAGElasticsearch()


# ========================================
# DICCIONARIO DE T√âRMINOS T√âCNICOS (ESPA√ëOL ‚Üî INGL√âS)
# ========================================

TERMINOS_TECNICOS = {
    # ===== FINANZAS CORPORATIVAS =====
    "wacc": ["WACC", "Weighted Average Cost of Capital", "costo promedio ponderado", "costo de capital"],
    "van": ["NPV", "VAN", "Net Present Value", "Valor Actual Neto", "valor presente neto"],
    "tir": ["IRR", "TIR", "Internal Rate of Return", "tasa interna de retorno"],
    "payback": ["Payback Period", "periodo de recuperaci√≥n", "payback"],
    "profitability_index": ["Profitability Index", "PI", "√≠ndice de rentabilidad", "√≠ndice de beneficio"],

    # ===== RENTA FIJA =====
    "bono": ["bond", "bono", "fixed income", "renta fija"],
    "cup√≥n": ["coupon", "cup√≥n"],
    "ytm": ["YTM", "yield to maturity", "rendimiento al vencimiento"],
    "duration": ["duration", "duraci√≥n", "Macaulay duration", "modified duration", "duration modificada"],
    "convexity": ["convexity", "convexidad"],
    "current_yield": ["current yield", "rendimiento corriente", "yield"],
    "zero_coupon": ["zero-coupon bond", "bono cup√≥n cero", "strip bond"],

    # ===== EQUITY =====
    "equity": ["equity", "acciones", "stock", "patrimonio"],
    "dividend": ["dividend", "dividendo"],
    "gordon": ["Gordon Growth", "modelo de Gordon", "dividend discount model", "DDM"],

    # ===== DERIVADOS =====
    "derivado": ["derivative", "derivado", "option", "opci√≥n"],
    "call": ["call option", "opci√≥n call"],
    "put": ["put option", "opci√≥n put"],
    "black-scholes": ["Black-Scholes", "Black Scholes"],
    "volatilidad": ["volatility", "volatilidad", "sigma"],
    "put_call_parity": ["put-call parity", "paridad put-call"],

    # ===== PORTAFOLIO =====
    "capm": ["CAPM", "Capital Asset Pricing Model", "modelo de valoraci√≥n de activos"],
    "beta": ["beta", "systematic risk", "riesgo sistem√°tico"],
    "sharpe": ["Sharpe ratio", "ratio de Sharpe", "rendimiento ajustado por riesgo"],
    "treynor": ["Treynor ratio", "ratio de Treynor", "√≠ndice de Treynor"],
    "jensen": ["Jensen's alpha", "Jensen alpha", "alfa de Jensen"],
    "portfolio": ["portfolio", "portafolio", "cartera"],
    "diversificaci√≥n": ["diversification", "diversificaci√≥n"],
    "correlaci√≥n": ["correlation", "correlaci√≥n", "covariance", "covarianza"],
    "riesgo": ["risk", "riesgo", "standard deviation", "desviaci√≥n est√°ndar"],
    "retorno": ["return", "retorno", "rendimiento", "expected return"],
}

# ========================================
# √çNDICE INVERSO PARA T√âRMINOS T√âCNICOS
# ========================================

def _construir_indice_inverso() -> dict:
    """
    Construye √≠ndice inverso para b√∫squeda O(1) de t√©rminos t√©cnicos.

    OPTIMIZACI√ìN: En lugar de buscar O(n¬≤) (palabra x t√©rmino),
    creamos un √≠ndice {palabra_lower: [claves]} para b√∫squeda O(1).

    Returns:
        Dict mapping palabra -> lista de claves en TERMINOS_TECNICOS
    """
    indice = {}
    for key, synonyms in TERMINOS_TECNICOS.items():
        for term in synonyms:
            # Normalizar t√©rmino (lower + split por espacios)
            palabras = term.lower().split()
            for palabra in palabras:
                if palabra not in indice:
                    indice[palabra] = []
                if key not in indice[palabra]:
                    indice[palabra].append(key)
    return indice

# Construir √≠ndice una sola vez al cargar el m√≥dulo
_INDICE_INVERSO = _construir_indice_inverso()
print(f"‚úÖ √çndice inverso construido: {len(_INDICE_INVERSO)} palabras -> t√©rminos t√©cnicos")


def enriquecer_query_bilingue(consulta: str) -> str:
    """
    Enriquece la consulta agregando t√©rminos t√©cnicos en ingl√©s si se detectan en espa√±ol.

    OPTIMIZACI√ìN: Usa √≠ndice inverso para b√∫squeda O(1) en lugar de O(n¬≤).

    Args:
        consulta: Query original del usuario (probablemente en espa√±ol)

    Returns:
        Query enriquecida con t√©rminos biling√ºes
    """
    consulta_lower = consulta.lower()
    palabras_query = consulta_lower.split()

    # Buscar t√©rminos t√©cnicos usando √≠ndice inverso (O(1) por palabra)
    claves_encontradas = set()
    for palabra in palabras_query:
        if palabra in _INDICE_INVERSO:
            claves_encontradas.update(_INDICE_INVERSO[palabra])

    # Si encontramos t√©rminos t√©cnicos, agregar todos sus sin√≥nimos
    if claves_encontradas:
        terminos_agregados = []
        for clave in claves_encontradas:
            terminos_agregados.extend(TERMINOS_TECNICOS[clave])

        # Eliminar duplicados manteniendo orden
        terminos_unicos = list(dict.fromkeys(terminos_agregados))
        terminos_str = " ".join(terminos_unicos)
        query_enriquecida = f"{consulta} {terminos_str}"
        print(f"üîÑ Query enriquecida: '{consulta}' ‚Üí agregados {len(terminos_unicos)} t√©rminos")
        return query_enriquecida

    return consulta


# ========================================
# HELPER: GENERAR VARIACIONES DE QUERY
# ========================================

def generar_variaciones_query(consulta: str) -> List[str]:
    """
    Genera variaciones de la query para b√∫squeda multi-query sin LLM.

    Estrategias:
    1. Query original (en espa√±ol)
    2. Query enriquecida con t√©rminos biling√ºes
    3. Query con palabras clave extra√≠das (solo sustantivos t√©cnicos)

    Args:
        consulta: Query original

    Returns:
        Lista de 2-3 variaciones de query
    """
    variaciones = []

    # Variaci√≥n 1: Query original
    variaciones.append(consulta)

    # Variaci√≥n 2: Query enriquecida con t√©rminos biling√ºes
    consulta_enriquecida = enriquecer_query_bilingue(consulta)
    if consulta_enriquecida != consulta:
        variaciones.append(consulta_enriquecida)

    # Variaci√≥n 3: Extraer palabras clave (acr√≥nimos y sustantivos t√©cnicos) - OPTIMIZADO
    import re
    # Buscar acr√≥nimos (2-5 letras may√∫sculas)
    acronimos = re.findall(r'\b[A-Z]{2,5}\b', consulta)

    # Buscar palabras t√©cnicas usando √≠ndice inverso (O(1) en lugar de O(n¬≤))
    palabras_query = consulta.lower().split()
    palabras_tecnicas = []

    for palabra in palabras_query:
        if palabra in _INDICE_INVERSO:
            # Encontrar claves relacionadas
            for clave in _INDICE_INVERSO[palabra]:
                # Agregar primera variante (t√≠picamente en ingl√©s)
                first_synonym = TERMINOS_TECNICOS[clave][0]
                if first_synonym not in palabras_tecnicas:
                    palabras_tecnicas.append(first_synonym)

    # Combinar acr√≥nimos + palabras t√©cnicas
    if acronimos or palabras_tecnicas:
        query_keywords = " ".join(acronimos + palabras_tecnicas)
        if query_keywords and query_keywords not in variaciones:
            variaciones.append(query_keywords)

    return variaciones


def buscar_multi_query_paralelo(consulta: str, k_per_query: int = 2) -> List[Document]:
    """
    Ejecuta m√∫ltiples variaciones de b√∫squeda EN PARALELO y combina resultados.

    OPTIMIZACIONES:
    - Genera 2-3 variaciones de query SIN LLM adicional
    - Ejecuta b√∫squedas en paralelo usando ThreadPoolExecutor
    - Deduplica resultados con SHA256 (m√°s robusto que hash())
    - Timeout de 10s por b√∫squeda para evitar colgarse
    - Retorna top-k m√°s relevantes

    Args:
        consulta: Query original del usuario
        k_per_query: Documentos a buscar por cada variaci√≥n (default: 2)

    Returns:
        Lista combinada de documentos √∫nicos (max 4-6 resultados)
    """
    from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError
    import hashlib

    print(f"üöÄ Multi-Query: Generando variaciones de '{consulta}'...")

    # Generar variaciones
    variaciones = generar_variaciones_query(consulta)
    print(f"   Variaciones generadas: {len(variaciones)}")
    for i, var in enumerate(variaciones, 1):
        print(f"   {i}. {var[:60]}...")

    # Ejecutar b√∫squedas en paralelo
    resultados_combinados = []
    contenidos_vistos = set()  # Para deduplicaci√≥n

    def buscar_variacion(query_var):
        """Funci√≥n helper para b√∫squeda en thread"""
        try:
            docs = rag_system.search_documents(query_var, k=k_per_query)
            return docs
        except Exception as e:
            print(f"‚ùå Error en b√∫squeda de variaci√≥n '{query_var[:30]}...': {e}")
            return []

    print(f"üîç Ejecutando {len(variaciones)} b√∫squedas en paralelo...")

    with ThreadPoolExecutor(max_workers=3) as executor:
        # Enviar todas las b√∫squedas en paralelo
        future_to_query = {
            executor.submit(buscar_variacion, var): var
            for var in variaciones
        }

        # Recolectar resultados a medida que completan
        for future in as_completed(future_to_query):
            query_var = future_to_query[future]
            try:
                # OPTIMIZACI√ìN: Agregar timeout de 10s para evitar colgarse
                docs = future.result(timeout=10)

                # Deduplicar por contenido
                for doc in docs:
                    # OPTIMIZACI√ìN: Usar SHA256 en lugar de hash() para mejor unicidad
                    content_hash = hashlib.sha256(
                        doc.page_content.encode('utf-8')
                    ).hexdigest()

                    if content_hash not in contenidos_vistos:
                        contenidos_vistos.add(content_hash)
                        resultados_combinados.append(doc)

            except TimeoutError:
                print(f"‚è±Ô∏è Timeout en b√∫squeda de '{query_var[:30]}...' (>10s)")
            except Exception as e:
                print(f"‚ùå Error procesando resultados de '{query_var[:30]}...': {e}")

    print(f"‚úÖ Multi-Query completado: {len(resultados_combinados)} documentos √∫nicos encontrados")

    # Retornar top-k resultados (m√°ximo 6 para no saturar)
    return resultados_combinados[:6]


# ========================================
# TOOL PARA EL AGENTE
# ========================================

@tool
def buscar_documentacion_financiera(consulta: str) -> str:
    """
    Busca informaci√≥n en material financiero usando MULTI-QUERY INTELIGENTE.

    OPTIMIZACI√ìN: Ejecuta 2-3 variaciones de b√∫squeda en PARALELO para mejorar recall
    sin aumentar latencia (b√∫squedas concurrentes vs secuenciales).

    Args:
        consulta: La pregunta o tema a buscar.

    Returns:
        Contexto relevante del material de estudio.
    """
    print(f"\nüîç RAG Tool (Multi-Query) invocado con consulta: '{consulta}'")

    # OPTIMIZACI√ìN: Multi-Query en paralelo (2-3 b√∫squedas concurrentes)
    docs = buscar_multi_query_paralelo(consulta, k_per_query=2)

    if not docs:
        return (
            "No encontr√© informaci√≥n relevante en el material de estudio indexado. "
            "Esto puede deberse a:\n"
            "1. El tema no est√° en el material indexado\n"
            "2. El √≠ndice no se ha generado a√∫n en Elasticsearch\n"
            "3. Problema de conexi√≥n con Elasticsearch\n"
            "4. La consulta necesita reformularse\n\n"
            "Intenta reformular tu pregunta o consulta directamente al "
            "agente especializado correspondiente."
        )

    # Formatear resultado (limitado a 4 fragmentos para no saturar)
    context_parts = []
    for i, doc in enumerate(docs[:4], 1):  # M√°ximo 4 fragmentos
        source = doc.metadata.get('source', 'Desconocido')
        content = doc.page_content.strip()

        # Extraer nombre del archivo
        if source != 'Desconocido':
            from pathlib import Path
            source_name = Path(source).name
        else:
            source_name = source

        # Metadata adicional
        cfa_level = doc.metadata.get('cfa_level', 'N/A')

        context_parts.append(
            f"--- Fragmento {i} ---\n"
            f"Fuente: {source_name}\n"
            f"CFA Level: {cfa_level}\n"
            f"Contenido:\n{content}"
        )

    full_context = "\n\n".join(context_parts)

    return f"üìö Informaci√≥n encontrada en el material de estudio:\n\n{full_context}"


print("‚úÖ M√≥dulo financial_rag_elasticsearch cargado (LangChain 1.0, OpenAI Embeddings).")